{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 10: Evaluating our Gesture Recognition NNs ðŸ•¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Jeff Che\n",
    "\n",
    "Student ID: 464957\n",
    "\n",
    "Collaborators: None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "In our _last_ homework (woohoo!), we will be analyzing and evaluating the gesture recognition data and models created in `Lab10`. This is a great opportunity to recap the **Data Science workflow** with all its major aspects: \n",
    "\n",
    "- exploratory data analysis (EDA) and data profiling\n",
    "- machine learning workkflow\n",
    "- training, validation, testing data\n",
    "- model comparison\n",
    "- presenting results (creating plot)\n",
    "\n",
    "It will be extremely helpful to review **Lab 10 (Gesture Recognition with Neural Networks)** first.\n",
    "\n",
    "In general, you should feel free to import any package that we have previously used in class. Ensure that all plots have the necessary components that a plot should have (e.g. axes labels, a title, a legend).\n",
    "\n",
    "Furthermore, in addition to recording your collaborators on this homework, please also remember to cite/indicate all external sources used when finishing this assignment. This includes peers, TAs, and links to online sources. Note that these citations will not free you from your obligation to submit your _own_ code and write-ups, however, they will be taken into account during the grading and regrading process.\n",
    "\n",
    "### Submission instructions\n",
    "* Submit this python notebook including your answers in the code cells as homework submission.\n",
    "* **Feel free to add as many cells as you need to** â€” just make sure you don't change what we gave you. \n",
    "* **Does it spark joy?** Note that you will be partially graded on the presentation (_cleanliness, clarity, comments_) of your notebook so make sure you [Marie Kondo](https://lifehacker.com/marie-kondo-is-not-a-verb-1833373654) your notebook before submitting it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "The data needed for this assignemnt can be found [here](https://wustl.box.com/s/q8mnl1o2zq2bh0ca5zajtk3msnu03ou8). All of it was gathered in `Homework 10 (Part I)`: \n",
    "- training\n",
    "- validation\n",
    "- augmented\n",
    "- testing\n",
    "\n",
    "Here are the neural network models trained on `training`:\n",
    "- cse217_v1.h5 (still training; watch for announcement on Piazza)\n",
    "- cse217_v2.h5 (still training; watch for announcement on Piazza)\n",
    "\n",
    "Here are the neural network models trained on `augmented`:\n",
    "- cse217_v1_augmented.h5 (still training; watch for announcement on Piazza)\n",
    "- cse217_v2_augmented.h5 (still training; watch for announcement on Piazza)\n",
    "\n",
    "Note that to train these models we used the `validation` dataset to determine when to stop the training process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test Data Collection, Data Profiling, and Model Understanding\n",
    "\n",
    "In this section, we will get a feel for our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 0\n",
    "\n",
    "Following the instructions in `Lab10_DataAquisition` take 15 images of rock, paper, and scissors gestures (cf. `1.1 How To Take The Pictures`) and scale them using the provided code (`1.2 Storing, Scaling, and Sharing the Images`). Store them in a folder called `testing` along with the already collected data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import makedirs, mkdir\n",
    "from os.path import exists\n",
    "\n",
    "base = 'utility/data'\n",
    "raw = f'{base}/raw'\n",
    "dirs = ['rock', 'paper', 'scissors']\n",
    "\n",
    "if not exists(raw):\n",
    "    makedirs(raw, exist_ok=True)\n",
    "\n",
    "for sign in dirs:\n",
    "    path = f'{raw}/{sign}'\n",
    "    \n",
    "    if not exists(path):\n",
    "        mkdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try this!** Store the images you took of rocks (âœŠ), papers (ðŸ¤š), and scissors (âœŒï¸) in the correct folders in `utility/data/raw`. Then, run the following cell to produced rescaled images, which will be stored in `utility/data/testing`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG_2748.JPG\n",
      "utility/data/raw/paper/IMG_2748.JPG\n",
      "utility/data/raw/paper/IMG_2748.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jche/anaconda3/lib/python3.7/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/Users/jche/anaconda3/lib/python3.7/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG_2742.JPG\n",
      "utility/data/raw/paper/IMG_2742.JPG\n",
      "utility/data/raw/paper/IMG_2742.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jche/anaconda3/lib/python3.7/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/Users/jche/anaconda3/lib/python3.7/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG_2754.JPG\n",
      "utility/data/raw/paper/IMG_2754.JPG\n",
      "utility/data/raw/paper/IMG_2754.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jche/anaconda3/lib/python3.7/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/Users/jche/anaconda3/lib/python3.7/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG_2751.JPG\n",
      "utility/data/raw/paper/IMG_2751.JPG\n",
      "utility/data/raw/paper/IMG_2751.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jche/anaconda3/lib/python3.7/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/Users/jche/anaconda3/lib/python3.7/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG_2745.JPG\n",
      "utility/data/raw/paper/IMG_2745.JPG\n",
      "utility/data/raw/paper/IMG_2745.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jche/anaconda3/lib/python3.7/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/Users/jche/anaconda3/lib/python3.7/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG_2741.JPG\n",
      "utility/data/raw/rock/IMG_2741.JPG\n",
      "utility/data/raw/rock/IMG_2741.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jche/anaconda3/lib/python3.7/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/Users/jche/anaconda3/lib/python3.7/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG_2744.JPG\n",
      "utility/data/raw/rock/IMG_2744.JPG\n",
      "utility/data/raw/rock/IMG_2744.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jche/anaconda3/lib/python3.7/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/Users/jche/anaconda3/lib/python3.7/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG_2750.JPG\n",
      "utility/data/raw/rock/IMG_2750.JPG\n",
      "utility/data/raw/rock/IMG_2750.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jche/anaconda3/lib/python3.7/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/Users/jche/anaconda3/lib/python3.7/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG_2753.JPG\n",
      "utility/data/raw/rock/IMG_2753.JPG\n",
      "utility/data/raw/rock/IMG_2753.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jche/anaconda3/lib/python3.7/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/Users/jche/anaconda3/lib/python3.7/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG_2747.JPG\n",
      "utility/data/raw/rock/IMG_2747.JPG\n",
      "utility/data/raw/rock/IMG_2747.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jche/anaconda3/lib/python3.7/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/Users/jche/anaconda3/lib/python3.7/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG_2749.JPG\n",
      "utility/data/raw/scissors/IMG_2749.JPG\n",
      "utility/data/raw/scissors/IMG_2749.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jche/anaconda3/lib/python3.7/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/Users/jche/anaconda3/lib/python3.7/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG_2743.JPG\n",
      "utility/data/raw/scissors/IMG_2743.JPG\n",
      "utility/data/raw/scissors/IMG_2743.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jche/anaconda3/lib/python3.7/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/Users/jche/anaconda3/lib/python3.7/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG_2755.JPG\n",
      "utility/data/raw/scissors/IMG_2755.JPG\n",
      "utility/data/raw/scissors/IMG_2755.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jche/anaconda3/lib/python3.7/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/Users/jche/anaconda3/lib/python3.7/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG_2746.JPG\n",
      "utility/data/raw/scissors/IMG_2746.JPG\n",
      "utility/data/raw/scissors/IMG_2746.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jche/anaconda3/lib/python3.7/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/Users/jche/anaconda3/lib/python3.7/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG_2752.JPG\n",
      "utility/data/raw/scissors/IMG_2752.JPG\n",
      "utility/data/raw/scissors/IMG_2752.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jche/anaconda3/lib/python3.7/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/Users/jche/anaconda3/lib/python3.7/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "from utility.util import load_image, resize_image, save_image\n",
    "\n",
    "\n",
    "testing = f'{base}/testing'\n",
    "\n",
    "for sign in dirs:\n",
    "    path = f'{testing}/{sign}'\n",
    "    \n",
    "    if not exists(path):\n",
    "        makedirs(path)\n",
    "for path, _, files in os.walk(raw):\n",
    "    sign = os.path.basename(path)\n",
    "    for file in files:\n",
    "        if '.DS_Store' not in file:\n",
    "            print(file)\n",
    "            input_path = f'{path}/{file}'\n",
    "            output_path = f'{testing}/{sign}/{file}'\n",
    "            print(input_path)\n",
    "            # note! warnings about lossy conversion are ok\n",
    "            image = load_image(input_path)\n",
    "            image = resize_image(image, (500, 500))\n",
    "            save_image(output_path, image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1\n",
    "\n",
    "**Write-up!**  Report the number of images per class in each of the four datasets. Are the dataset balanced? No code submission required.\n",
    "> Hint: For most of this you can use the code from `Lab10_Model` with light modifications. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "                  | training | validation | testing | augmented\n",
    "        rock (c0) |     266  |        66  |    5    | 1243\n",
    "       paper (c1) |     260  |        67  |    5    | 1257\n",
    "    scissors (c2) |     264  |        66  |    5    | 1262\n",
    "\n",
    "\n",
    "# your response here\n",
    "Looking at the box folders containing the relevant data sets, I reported the number of each in the table above. The data sets are not perfectly balanced, but I would say they are all very close where it should be ok that they are off a tiny bit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "Now, let's look at our models. \n",
    "\n",
    "**Write-up!**  Compare the following statistics for all four models: \n",
    "- number of parameters\n",
    "- number of convolutional layers\n",
    "- number of dense layers\n",
    "- size of the model (`.h5`) file \n",
    "\n",
    "What are the most surprising aspects of these statistics to you? "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "                      | # parameters | # conv layers | # dense layers | file size\n",
    "            cse217_v1 |  24,615      |  1060         |    23555       |  369 KB\n",
    "            cse217_v2 |  1,741,571   |  1478912      |    262659      |  21 MB   \n",
    "  cse217_v1_augmented |  24,615      |  1060         |    23555       |  369 KB\n",
    "  cse217_v2_augmented |  1,741,571   |  1478912      |    262659      |  21 MB\n",
    "\n",
    "\n",
    "# your response here\n",
    "\n",
    "The v2 of the models are so much larger than the v1s. Nearly 72 times larger in terms of parameters, about 57 times larger in terms of file size. Beyond that, I didn't really think to expect v1 and v1_aug to have the same number of parameters, conv and dense layers, and same size but it makes sense (v2 and v2_aug too) since same number of inputs, just more variety. Code used to determine this is in the two cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "training_model_path = 'utility/models/training'\n",
    "aug_model_path = 'utility/models/augmented'\n",
    "cse217_v1 = load_model(f'{training_model_path}/cse217_v1.h5', compile=True)\n",
    "cse217_v2 = load_model(f'{training_model_path}/cse217_v2.h5', compile=True)\n",
    "cse217_v1_augmented = load_model(f'{aug_model_path}/cse217_v1_augmented.h5', compile=True)\n",
    "cse217_v2_augmented = load_model(f'{aug_model_path}/cse217_v2_augmented.h5', compile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cse217_v1.summary()\n",
    "# cse217_v2.summary()\n",
    "# cse217_v1_augmented.summary()\n",
    "# cse217_v2_augmented.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Comparison: v1 vs v2\n",
    "\n",
    "By now we should know all of the ins and outs about our datasets and models (right?). Let's evaluate and compare the models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3\n",
    "\n",
    "First let's investiage which of the two versions `cse217_v1` or `cse217_v2` performs better in the non-augmented setting. You can use the code provided in the *updated version* of  `Lab10_Model` under `5. Evaluate Neural Network on Validation Data` with light modifications. \n",
    "\n",
    "**Write-up** For both versions report the accuracy on all three datasets `training`, `validation`, and `testing` and summarize your findings. \n",
    "- Which model performs better? Justify your answer based on the presented accuraccies. \n",
    "- Argue whether we can be happy with the perfomrance of our model. If yes, justify why, if no, give suggestions on how to imporve the performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, we provide an example of how to load the testing. Note the dimensions of the dataset (especially the size of the images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utility/data/testing/paper/IMG_2748.JPG\n",
      "utility/data/testing/paper/IMG_2742.JPG\n",
      "utility/data/testing/paper/IMG_2754.JPG\n",
      "utility/data/testing/paper/IMG_2751.JPG\n",
      "utility/data/testing/paper/IMG_2745.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jche/anaconda3/lib/python3.7/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/Users/jche/anaconda3/lib/python3.7/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utility/data/testing/rock/IMG_2741.JPG\n",
      "utility/data/testing/rock/IMG_2744.JPG\n",
      "utility/data/testing/rock/IMG_2750.JPG\n",
      "utility/data/testing/rock/IMG_2753.JPG\n",
      "utility/data/testing/rock/IMG_2747.JPG\n",
      "utility/data/testing/scissors/IMG_2749.JPG\n",
      "utility/data/testing/scissors/IMG_2743.JPG\n",
      "utility/data/testing/scissors/IMG_2755.JPG\n",
      "utility/data/testing/scissors/IMG_2746.JPG\n",
      "utility/data/testing/scissors/IMG_2752.JPG\n",
      "utility/data/training/paper/IMG_7436.jpeg\n",
      "utility/data/training/paper/IMG_0996.JPG\n",
      "utility/data/training/paper/IMG_5150.jpg\n",
      "utility/data/training/paper/IMG_1849.jpg\n",
      "utility/data/training/paper/IMG_0598.jpeg\n",
      "utility/data/training/paper/paper5n.jpg\n",
      "utility/data/training/paper/IMG_6636.jpeg\n",
      "utility/data/training/paper/IMG_6266.jpeg\n",
      "utility/data/training/paper/IMG_6504.jpg\n",
      "utility/data/training/paper/paper2jche.JPG\n",
      "utility/data/training/paper/IMG_7322.jpeg\n",
      "utility/data/training/paper/20200420_184236.jpg\n",
      "utility/data/training/paper/IMG_20200423_204825.jpg\n",
      "utility/data/training/paper/Paper.jpg\n",
      "utility/data/training/paper/paper3zzhao.jpg\n",
      "utility/data/training/paper/IMG_1451.JPG\n",
      "utility/data/training/paper/IMG_0997.JPG\n",
      "utility/data/training/paper/IMG_5151.jpg\n",
      "utility/data/training/paper/paper2zzhao.jpg\n",
      "utility/data/training/paper/IMG_2116.jpeg\n",
      "utility/data/training/paper/IMG_5386.jpg\n",
      "utility/data/training/paper/IMG_1651.jpg\n",
      "utility/data/training/paper/IMG_0097.jpeg\n",
      "utility/data/training/paper/IMG_7142.PNG\n",
      "utility/data/training/paper/IMG_5225.jpg\n",
      "utility/data/training/paper/IMG_6512.jpg\n",
      "utility/data/training/paper/IMG_1527.jpg\n",
      "utility/data/training/paper/IMG_20200423_151108112.jpg\n",
      "utility/data/training/paper/IMG-1981.jpg\n",
      "utility/data/training/paper/IMG_2588.jpg\n",
      "utility/data/training/paper/IMG_1650.jpg\n",
      "utility/data/training/paper/IMG_1644.jpg\n",
      "utility/data/training/paper/IMG_5387.jpg\n",
      "utility/data/training/paper/IMG_20200423_204601.jpg\n",
      "utility/data/training/paper/IMG-6468 (1).jpg\n",
      "utility/data/training/paper/IMG_9988.jpg\n",
      "utility/data/training/paper/Image 11.jpeg\n",
      "utility/data/training/paper/PAPER1LAB10.jpg\n",
      "utility/data/training/paper/94128039_177562080037773_1466744195011051520_n.jpg\n",
      "utility/data/training/paper/IMG_1641.jpg\n",
      "utility/data/training/paper/IMG_9989.jpg\n",
      "utility/data/training/paper/IMG_6338.JPG\n",
      "utility/data/training/paper/IMG_20200423_151039519.jpg\n",
      "utility/data/training/paper/IMG_20200423_151114845.jpg\n",
      "utility/data/training/paper/IMG_1643.jpg\n",
      "utility/data/training/paper/IMG_1938.JPG\n",
      "utility/data/training/paper/IMG_2028.JPG\n",
      "utility/data/training/paper/IMG-1978.jpg\n",
      "utility/data/training/paper/IMG_1254 2.jpeg\n",
      "utility/data/training/paper/paper3jche.JPG\n",
      "utility/data/training/paper/20200420_184233.jpg\n",
      "utility/data/training/paper/IMG_7145.PNG\n",
      "utility/data/training/paper/IMG_3647-Copy1.jpg\n",
      "utility/data/training/paper/94207753_959390134481555_1516703722749558784_n.jpg\n",
      "utility/data/training/paper/IMG_7437.jpeg\n",
      "utility/data/training/paper/IMG_0088.jpg\n",
      "utility/data/training/paper/IMG_0705.jpg\n",
      "utility/data/training/paper/thumbnail_IMG_0350.jpg\n",
      "utility/data/training/paper/IMG_1534.HEIC\n",
      "utility/data/training/paper/WIN_20200420_20_29_39_Pro.jpg\n",
      "utility/data/training/paper/IMG_9319.jpg\n",
      "utility/data/training/paper/Paper4.jpg\n",
      "utility/data/training/paper/paper5.jpg\n",
      "utility/data/training/paper/IMG_9318.jpg\n",
      "utility/data/training/paper/thumbnail_IMG_0345.jpg\n",
      "utility/data/training/paper/IMG_3557.jpg\n",
      "utility/data/training/paper/thumbnail_IMG_0351.jpg\n",
      "utility/data/training/paper/IMG_0704.jpg\n",
      "utility/data/training/paper/IMG_2215.jpeg\n",
      "utility/data/training/paper/IMG_0089.jpg\n",
      "utility/data/training/paper/IMG_0706.jpg\n",
      "utility/data/training/paper/IMG_5468.JPG\n",
      "utility/data/training/paper/paper10.jpg\n",
      "utility/data/training/paper/paper3n.jpg\n",
      "utility/data/training/paper/IMG_7135.PNG\n",
      "utility/data/training/paper/IMG_20200423_151110515.jpg\n",
      "utility/data/training/paper/paper7.jpg\n",
      "utility/data/training/paper/IMG_1578.JPG\n",
      "utility/data/training/paper/IMG_7135.JPG\n",
      "utility/data/training/paper/IMG_7134.JPG\n",
      "utility/data/training/paper/IMG_2064.jpg\n",
      "utility/data/training/paper/wpaper2.jpg\n",
      "utility/data/training/paper/WeChat Image_20200424001459.jpg\n",
      "utility/data/training/paper/IMG_5469.JPG\n",
      "utility/data/training/paper/WeChat Image_20200424001505.jpg\n",
      "utility/data/training/paper/WeChat Image_20200424001511.jpg\n",
      "utility/data/training/paper/IMG_2219.jpeg\n",
      "utility/data/training/paper/IMG_3554.jpg\n",
      "utility/data/training/paper/paper1jche.JPG\n",
      "utility/data/training/paper/IMG_4213.JPG\n",
      "utility/data/training/paper/IMG_0908.JPG\n",
      "utility/data/training/paper/IMG_2218.jpeg\n",
      "utility/data/training/paper/IMG_0703.jpg\n",
      "utility/data/training/paper/Photo on 4-23-20 at 7.21 AM.jpg\n",
      "utility/data/training/paper/WIN_20200420_20_29_43_Pro.jpg\n",
      "utility/data/training/paper/IMG_2060.jpg\n",
      "utility/data/training/paper/Paper2.jpg\n",
      "utility/data/training/paper/IMG_2061.jpg\n",
      "utility/data/training/paper/Paper3.jpg\n",
      "utility/data/training/paper/IMG_7131.JPG\n",
      "utility/data/training/paper/paper2n.jpg\n",
      "utility/data/training/paper/paper4zzhao.jpg\n",
      "utility/data/training/paper/IMG_0702.jpg\n",
      "utility/data/training/paper/IMG_3673-Copy1.jpg\n",
      "utility/data/training/paper/Photo on 4-22-20 at 2.28 PM #2.jpg\n",
      "utility/data/training/paper/IMG_1634.jpg\n",
      "utility/data/training/paper/20200420_184245.jpg\n",
      "utility/data/training/paper/IMG_0338.jpg\n",
      "utility/data/training/paper/IMG_9320.jpg\n",
      "utility/data/training/paper/IMG_7133.JPG\n",
      "utility/data/training/paper/IMG_0112.JPG\n",
      "utility/data/training/paper/paper1.jpg\n",
      "utility/data/training/paper/paper0.jpg\n",
      "utility/data/training/paper/IMG_2062.jpg\n",
      "utility/data/training/paper/IMG_9335.jpg\n",
      "utility/data/training/paper/wpaper4.jpg\n",
      "utility/data/training/paper/IMG_8017.JPG\n",
      "utility/data/training/paper/IMG_3803.JPG\n",
      "utility/data/training/paper/IMG_1535.HEIC\n",
      "utility/data/training/paper/IMG_1635.jpg\n",
      "utility/data/training/paper/Photo on 4-22-20 at 2.28 PM #3.jpg\n",
      "utility/data/training/paper/IMG_2658.jpg\n",
      "utility/data/training/paper/IMG_2217.jpeg\n",
      "utility/data/training/paper/IMG_2655.jpg\n",
      "utility/data/training/paper/p3.jpg\n",
      "utility/data/training/paper/IMG_0485.JPG\n",
      "utility/data/training/paper/IMG_6645.jpeg\n",
      "utility/data/training/paper/IMG_6023.jpg\n",
      "utility/data/training/paper/tpaper1.jpg\n",
      "utility/data/training/paper/Image 14.jpeg\n",
      "utility/data/training/paper/paper4paper.jpg\n",
      "utility/data/training/paper/IMG_8027.JPG\n",
      "utility/data/training/paper/IMG_6022.jpg\n",
      "utility/data/training/paper/paper33.jpg\n",
      "utility/data/training/paper/p2.jpg\n",
      "utility/data/training/paper/IMG_2654.jpg\n",
      "utility/data/training/paper/IMG_2656.jpg\n",
      "utility/data/training/paper/IMG_3548.jpg\n",
      "utility/data/training/paper/IMG_3212.jpg\n",
      "utility/data/training/paper/94458623_245476626576357_152227968981139456_n.jpg\n",
      "utility/data/training/paper/IMG_3560.jpg\n",
      "utility/data/training/paper/IMG_8569.JPG\n",
      "utility/data/training/paper/IMG_3676-Copy1.jpg\n",
      "utility/data/training/paper/IMG_0120.JPG\n",
      "utility/data/training/paper/rescaled4.jpg\n",
      "utility/data/training/paper/tpaper3.jpg\n",
      "utility/data/training/paper/PAPER2LAB10.jpg\n",
      "utility/data/training/paper/PAPER3LAB10.jpg\n",
      "utility/data/training/paper/paper2345345.jpg\n",
      "utility/data/training/paper/paper1n.jpg\n",
      "utility/data/training/paper/p1.jpg\n",
      "utility/data/training/paper/IMG_3213.JPG\n",
      "utility/data/training/paper/IMG_2657.jpg\n",
      "utility/data/training/paper/IMG_2653.jpg\n",
      "utility/data/training/paper/IMG_6275.jpeg\n",
      "utility/data/training/paper/WeChat Image_20200424001508.jpg\n",
      "utility/data/training/paper/Photo on 4-23-20 at 7.26 AM.jpg\n",
      "utility/data/training/paper/IMG_5470.JPG\n",
      "utility/data/training/paper/p5.jpg\n",
      "utility/data/training/paper/94258301_266924464470492_2966573674154426368_n.jpg\n",
      "utility/data/training/paper/IMG_7139.PNG\n",
      "utility/data/training/paper/IMG_6025.jpg\n",
      "utility/data/training/paper/IMG_1986.jpg\n",
      "utility/data/training/paper/paper4jche.JPG\n",
      "utility/data/training/paper/rescaled1.jpg\n",
      "utility/data/training/paper/IMG_0119.JPG\n",
      "utility/data/training/paper/IMG_1575.JPG\n",
      "utility/data/training/paper/IMG_6024.jpg\n",
      "utility/data/training/paper/p4.jpg\n",
      "utility/data/training/paper/IMG_0910.JPG\n",
      "utility/data/training/paper/WIN_20200420_20_29_47_Pro.jpg\n",
      "utility/data/training/paper/IMG_0906.JPG\n",
      "utility/data/training/paper/IMG_0090.jpg\n",
      "utility/data/training/paper/IMG_3214.JPG\n",
      "utility/data/training/paper/IMG_8725.jpeg\n",
      "utility/data/training/paper/thumbnail_IMG_0348.jpg\n",
      "utility/data/training/paper/IMG_5467.JPG\n",
      "utility/data/training/paper/IMG_1577.JPG\n",
      "utility/data/training/paper/IMG_0133.JPG\n",
      "utility/data/training/paper/rescaled3.jpg\n",
      "utility/data/training/paper/rescaled2.jpg\n",
      "utility/data/training/paper/IMG_1576.JPG\n",
      "utility/data/training/paper/IMG_0867.JPG\n",
      "utility/data/training/paper/paper22.jpg\n",
      "utility/data/training/paper/IMG_20200423_204645.jpg\n",
      "utility/data/training/paper/thumbnail_IMG_0349.jpg\n",
      "utility/data/training/paper/IMG_3215.JPG\n",
      "utility/data/training/paper/paper1zzhao.jpg\n",
      "utility/data/training/paper/IMG_0907.JPG\n",
      "utility/data/training/paper/4.jpg\n",
      "utility/data/training/paper/IMG_6336.JPG\n",
      "utility/data/training/paper/IMG_1897.jpg\n",
      "utility/data/training/paper/IMG_2434.jpg\n",
      "utility/data/training/paper/IMG_5373.jpg\n",
      "utility/data/training/paper/IMG-1975.jpg\n",
      "utility/data/training/paper/IMG_6524.jpg\n",
      "utility/data/training/paper/IMG_2019.JPG\n",
      "utility/data/training/paper/IMG_2025.JPG\n",
      "utility/data/training/paper/Paper 1.jpg\n",
      "utility/data/training/paper/WIN_20200420_20_29_45_Pro.jpg\n",
      "utility/data/training/paper/paper44.jpg\n",
      "utility/data/training/paper/IMG_1896.jpg\n",
      "utility/data/training/paper/IMG_4911.jpg\n",
      "utility/data/training/paper/IMG_1855.jpg\n",
      "utility/data/training/paper/IMG_9992.jpg\n",
      "utility/data/training/paper/IMG_6337.JPG\n",
      "utility/data/training/paper/IMG_7434.jpeg\n",
      "utility/data/training/paper/5.jpg\n",
      "utility/data/training/paper/IMG_4285.jpg\n",
      "utility/data/training/paper/IMG_6335.JPG\n",
      "utility/data/training/paper/IMG_7759.jpg\n",
      "utility/data/training/paper/IMG_9990.jpg\n",
      "utility/data/training/paper/Photo on 4-23-20 at 7.26 AM #2.jpg\n",
      "utility/data/training/paper/IMG_1894.jpg\n",
      "utility/data/training/paper/IMG_5370.jpg\n",
      "utility/data/training/paper/Photo on 4-22-20 at 2.27 PM #6.jpg\n",
      "utility/data/training/paper/Paper 3.jpg\n",
      "utility/data/training/paper/Paper 2.jpg\n",
      "utility/data/training/paper/Image 12.jpeg\n",
      "utility/data/training/paper/Photo on 4-22-20 at 2.27 PM #7.jpg\n",
      "utility/data/training/paper/IMG_5371.jpg\n",
      "utility/data/training/paper/IMG_1895.jpg\n",
      "utility/data/training/paper/IMG_4912.jpg\n",
      "utility/data/training/paper/IMG_4286.jpg\n",
      "utility/data/training/paper/IMG_4282.jpg\n",
      "utility/data/training/paper/2.jpg\n",
      "utility/data/training/paper/IMG_0999.JPG\n",
      "utility/data/training/paper/IMG_1846.jpg\n",
      "utility/data/training/paper/IMG_1852.jpg\n",
      "utility/data/training/paper/d.png\n",
      "utility/data/training/paper/IMG_1649.jpg\n",
      "utility/data/training/paper/IMG_1531.HEIC\n",
      "utility/data/training/paper/IMG_6269.jpeg\n",
      "utility/data/training/paper/IMG_6639.jpeg\n",
      "utility/data/training/paper/IMG_6522.jpg\n",
      "utility/data/training/paper/Image 13.jpeg\n",
      "utility/data/training/paper/IMG_2023.JPG\n",
      "utility/data/training/paper/94624216_159517542104879_9146173040546021376_n.jpg\n",
      "utility/data/training/paper/IMG_0344.jpg\n",
      "utility/data/training/paper/IMG_0350.jpg\n",
      "utility/data/training/paper/paper3paper.jpg\n",
      "utility/data/training/paper/20200420_184239.jpg\n",
      "utility/data/training/paper/IMG_6642.jpeg\n",
      "utility/data/training/paper/e.png\n",
      "utility/data/training/paper/IMG_5374.jpg\n",
      "utility/data/training/paper/IMG_0998.JPG\n",
      "utility/data/training/paper/3.jpg\n",
      "utility/data/training/paper/IMG_4283.jpg\n",
      "utility/data/training/paper/IMG_7435.jpeg\n",
      "utility/data/training/paper/1.jpg\n",
      "utility/data/training/paper/IMG_5148.jpg\n",
      "utility/data/training/paper/IMG_6273.jpeg\n",
      "utility/data/training/paper/IMG_5389.jpg\n",
      "utility/data/training/paper/g.png\n",
      "utility/data/training/paper/IMG-6464 (1).jpg\n",
      "utility/data/training/paper/IMG_20200423_204753.jpg\n",
      "utility/data/training/paper/IMG_3650-Copy1.jpg\n",
      "utility/data/training/paper/IMG_0346.jpg\n",
      "utility/data/training/paper/Paper 4.jpg\n",
      "utility/data/training/paper/Photo on 4-23-20 at 7.20 AM #2.jpg\n",
      "utility/data/training/paper/IMG-1971.jpg\n",
      "utility/data/training/paper/Photo on 4-23-20 at 7.20 AM.jpg\n",
      "utility/data/training/paper/PAPER5LAB10.jpg\n",
      "utility/data/training/paper/f.png\n",
      "utility/data/training/paper/IMG_5388.jpg\n",
      "utility/data/training/paper/IMG_5149.jpg\n",
      "utility/data/training/rock/IMG_2603.jpg\n",
      "utility/data/training/rock/rock1zzhao.jpg\n",
      "utility/data/training/rock/IMG_5391.jpg\n",
      "utility/data/training/rock/IMG_1652.jpg\n",
      "utility/data/training/rock/IMG_1646.jpg\n",
      "utility/data/training/rock/IMG_7141.PNG\n",
      "utility/data/training/rock/IMG_20200423_205119.jpg\n",
      "utility/data/training/rock/IMG_1518.jpg\n",
      "utility/data/training/rock/IMG_6505.jpg\n",
      "utility/data/training/rock/IMG_7140.JPG\n",
      "utility/data/training/rock/IMG_1519.jpg\n",
      "utility/data/training/rock/IMG_6510.jpg\n",
      "utility/data/training/rock/rock4jche.JPG\n",
      "utility/data/training/rock/IMG_1848.jpg\n",
      "utility/data/training/rock/IMG_7034.JPG\n",
      "utility/data/training/rock/IMG_5153.jpg\n",
      "utility/data/training/rock/IMG_5392.jpg\n",
      "utility/data/training/rock/IMG_1645.jpg\n",
      "utility/data/training/rock/IMG-1980.jpg\n",
      "utility/data/training/rock/IMG_9961.jpeg\n",
      "utility/data/training/rock/rock5n.jpg\n",
      "utility/data/training/rock/IMG_6507.jpg\n",
      "utility/data/training/rock/IMG_0348.jpg\n",
      "utility/data/training/rock/IMG_6641.jpeg\n",
      "utility/data/training/rock/IMG_5393.jpg\n",
      "utility/data/training/rock/IMG_2836.jpg\n",
      "utility/data/training/rock/IMG_0990.JPG\n",
      "utility/data/training/rock/IMG_5156.jpg\n",
      "utility/data/training/rock/IMG_1640.jpg\n",
      "utility/data/training/rock/ROCK2LAB10.jpg\n",
      "utility/data/training/rock/ROCK3LAB10.jpg\n",
      "utility/data/training/rock/IMG_1907.jpg\n",
      "utility/data/training/rock/rock4n.jpg\n",
      "utility/data/training/rock/IMG_2572.jpg\n",
      "utility/data/training/rock/IMG_1906.jpg\n",
      "utility/data/training/rock/WIN_20200420_20_29_14_Pro.jpg\n",
      "utility/data/training/rock/IMG_0991.JPG\n",
      "utility/data/training/rock/IMG_4288.jpg\n",
      "utility/data/training/rock/IMG_5155.jpg\n",
      "utility/data/training/rock/IMG_0993.JPG\n",
      "utility/data/training/rock/IMG_5394.jpg\n",
      "utility/data/training/rock/IMG_4908.jpg\n",
      "utility/data/training/rock/IMG_5357.jpg\n",
      "utility/data/training/rock/IMG_7144.PNG\n",
      "utility/data/training/rock/IMG_1904.jpg\n",
      "utility/data/training/rock/IMG_20200423_151106110.jpg\n",
      "utility/data/training/rock/qqqq.png\n",
      "utility/data/training/rock/IMG_4470.JPG\n",
      "utility/data/training/rock/IMG_2029.JPG\n",
      "utility/data/training/rock/IMG_1520.jpg\n",
      "utility/data/training/rock/IMG_7186.JPG\n",
      "utility/data/training/rock/IMG_2798.JPG\n",
      "utility/data/training/rock/IMG_1905.jpg\n",
      "utility/data/training/rock/IMG_2224.jpeg\n",
      "utility/data/training/rock/IMG_6267.jpeg\n",
      "utility/data/training/rock/IMG_4909.jpg\n",
      "utility/data/training/rock/IMG_6271.jpeg\n",
      "utility/data/training/rock/IMG_5154.jpg\n",
      "utility/data/training/rock/IMG_0992.JPG\n",
      "utility/data/training/rock/IMG_4289.jpg\n",
      "utility/data/training/rock/IMG_2660.jpg\n",
      "utility/data/training/rock/94377537_2542546856000210_6059336652856229888_n.jpg\n",
      "utility/data/training/rock/IMG_3556.jpg\n",
      "utility/data/training/rock/IMG_5480.JPG\n",
      "utility/data/training/rock/r2.jpg\n",
      "utility/data/training/rock/Rock3.jpg\n",
      "utility/data/training/rock/IMG_7136.PNG\n",
      "utility/data/training/rock/IMG_9325.jpg\n",
      "utility/data/training/rock/ROCK4LAB10.jpg\n",
      "utility/data/training/rock/IMG_2066.jpg\n",
      "utility/data/training/rock/rock11.jpg\n",
      "utility/data/training/rock/rock10.jpg\n",
      "utility/data/training/rock/wrock1.jpg\n",
      "utility/data/training/rock/IMG_7137.JPG\n",
      "utility/data/training/rock/IMG_2067.jpg\n",
      "utility/data/training/rock/IMG_9324.jpg\n",
      "utility/data/training/rock/20200420_184255.jpg\n",
      "utility/data/training/rock/IMG_6956.JPG\n",
      "utility/data/training/rock/IMG_7490.JPG\n",
      "utility/data/training/rock/Rock2.jpg\n",
      "utility/data/training/rock/r3.jpg\n",
      "utility/data/training/rock/IMG_5481.JPG\n",
      "utility/data/training/rock/IMG_6349.JPG\n",
      "utility/data/training/rock/IMG_2429.jpeg\n",
      "utility/data/training/rock/IMG_2661.jpg\n",
      "utility/data/training/rock/IMG_2850.jpg\n",
      "utility/data/training/rock/IMG_7430.jpeg\n",
      "utility/data/training/rock/IMG_2663.jpg\n",
      "utility/data/training/rock/thumbnail_IMG_0347.jpg\n",
      "utility/data/training/rock/IMG_6276.jpeg\n",
      "utility/data/training/rock/IMG_6149.jpg\n",
      "utility/data/training/rock/IMG_4027.jpeg\n",
      "utility/data/training/rock/r1.jpg\n",
      "utility/data/training/rock/IMG_2223.jpeg\n",
      "utility/data/training/rock/IMG_6029.jpg\n",
      "utility/data/training/rock/94124108_2948170608598983_5890870207097864192_n.jpg\n",
      "utility/data/training/rock/IMG_0128.JPG\n",
      "utility/data/training/rock/wrock3.jpg\n",
      "utility/data/training/rock/wrock2.jpg\n",
      "utility/data/training/rock/IMG_0129.JPG\n",
      "utility/data/training/rock/IMG_6028.jpg\n",
      "utility/data/training/rock/IMG_9333.jpg\n",
      "utility/data/training/rock/IMG_3675-Copy1.jpg\n",
      "utility/data/training/rock/Rock1.jpg\n",
      "utility/data/training/rock/IMG_2662.jpg\n",
      "utility/data/training/rock/IMG_3550.jpg\n",
      "utility/data/training/rock/thumbnail_IMG_0356.jpg\n",
      "utility/data/training/rock/IMG_2666.jpg\n",
      "utility/data/training/rock/rock5.jpg\n",
      "utility/data/training/rock/IMG_1637.jpg\n",
      "utility/data/training/rock/r4.jpg\n",
      "utility/data/training/rock/IMG_5479.JPG\n",
      "utility/data/training/rock/WIN_20200420_20_29_21_Pro.jpg\n",
      "utility/data/training/rock/IMG_7332.jpg\n",
      "utility/data/training/rock/IMG_9323.jpg\n",
      "utility/data/training/rock/IMG_1582.JPG\n",
      "utility/data/training/rock/IMG_7119.JPG\n",
      "utility/data/training/rock/IMG_1583.JPG\n",
      "utility/data/training/rock/Rock.jpg\n",
      "utility/data/training/rock/IMG_2222.jpeg\n",
      "utility/data/training/rock/IMG_5478.JPG\n",
      "utility/data/training/rock/IMG_1636.jpg\n",
      "utility/data/training/rock/rock4rock.jpg\n",
      "utility/data/training/rock/Rock4.jpg\n",
      "utility/data/training/rock/IMG_9281.JPG\n",
      "utility/data/training/rock/thumbnail_IMG_0357.jpg\n",
      "utility/data/training/rock/IMG_7431.jpeg\n",
      "utility/data/training/rock/IMG_3553.jpg\n",
      "utility/data/training/rock/IMG_2665.jpg\n",
      "utility/data/training/rock/20200420_184251.jpg\n",
      "utility/data/training/rock/IMG_20200423_151100714.jpg\n",
      "utility/data/training/rock/IMG_1581.JPG\n",
      "utility/data/training/rock/rock2n.jpg\n",
      "utility/data/training/rock/wrock4.jpg\n",
      "utility/data/training/rock/IMG_1580.JPG\n",
      "utility/data/training/rock/WIN_20200420_20_29_17_Pro.jpg\n",
      "utility/data/training/rock/IMG_2664.jpg\n",
      "utility/data/training/rock/Photo on 4-22-20 at 2.26 PM #5.jpg\n",
      "utility/data/training/rock/IMG_5751.jpeg\n",
      "utility/data/training/rock/thumbnail_IMG_0359.jpg\n",
      "utility/data/training/rock/IMG_3563.jpg\n",
      "utility/data/training/rock/IMG_3646-Copy1 (1).jpg\n",
      "utility/data/training/rock/20200420_184249.jpg\n",
      "utility/data/training/rock/IMG_0693.jpg\n",
      "utility/data/training/rock/rock1n.jpg\n",
      "utility/data/training/rock/img4.jpg\n",
      "utility/data/training/rock/IMG_0692.jpg\n",
      "utility/data/training/rock/thumbnail_IMG_0358.jpg\n",
      "utility/data/training/rock/Photo on 4-22-20 at 2.26 PM #4.jpg\n",
      "utility/data/training/rock/rock3jche.JPG\n",
      "utility/data/training/rock/IMG_0914.JPG\n",
      "utility/data/training/rock/IMG_9379.jpeg\n",
      "utility/data/training/rock/Photo on 4-23-20 at 7.28 AM.jpg\n",
      "utility/data/training/rock/ROCK1LAB10.jpg\n",
      "utility/data/training/rock/rock1rock.jpg\n",
      "utility/data/training/rock/IMG-6466 (1).jpg\n",
      "utility/data/training/rock/Photo on 4-23-20 at 7.27 AM #2.jpg\n",
      "utility/data/training/rock/Photo on 4-23-20 at 7.27 AM #3.jpg\n",
      "utility/data/training/rock/WIN_20200420_20_29_24_Pro.jpg\n",
      "utility/data/training/rock/IMG_0336.jpg\n",
      "utility/data/training/rock/IMG_2221.jpeg\n",
      "utility/data/training/rock/rock8.jpg\n",
      "utility/data/training/rock/IMG_0915.JPG\n",
      "utility/data/training/rock/IMG_7432.jpeg\n",
      "utility/data/training/rock/qqq.png\n",
      "utility/data/training/rock/IMG_0083.jpg\n",
      "utility/data/training/rock/Image.jpeg\n",
      "utility/data/training/rock/IMG_3571.JPG\n",
      "utility/data/training/rock/Photo on 4-22-20 at 2.26 PM #3.jpg\n",
      "utility/data/training/rock/IMG_6347.JPG\n",
      "utility/data/training/rock/rock2jche.JPG\n",
      "utility/data/training/rock/WeChat Image_20200424001440.jpg\n",
      "utility/data/training/rock/img3.jpg\n",
      "utility/data/training/rock/IMG_0695.jpg\n",
      "utility/data/training/rock/IMG_2069.jpg\n",
      "utility/data/training/rock/IMG_7139.JPG\n",
      "utility/data/training/rock/IMG_7138.JPG\n",
      "utility/data/training/rock/IMG_0131.JPG\n",
      "utility/data/training/rock/IMG_2068.jpg\n",
      "utility/data/training/rock/Image 3.jpeg\n",
      "utility/data/training/rock/IMG_0694.jpg\n",
      "utility/data/training/rock/img2.jpg\n",
      "utility/data/training/rock/Photo on 4-23-20 at 7.27 AM #6.jpg\n",
      "utility/data/training/rock/IMG_6030.jpg\n",
      "utility/data/training/rock/IMG_7138.PNG\n",
      "utility/data/training/rock/20200420_184306.jpg\n",
      "utility/data/training/rock/Photo on 4-22-20 at 2.26 PM #2.jpg\n",
      "utility/data/training/rock/IMG_6346.JPG\n",
      "utility/data/training/rock/IMG_3570.jpg\n",
      "utility/data/training/rock/IMG_0086.jpg\n",
      "utility/data/training/rock/qq.png\n",
      "utility/data/training/rock/IMG_0912.JPG\n",
      "utility/data/training/rock/IMG_0084.jpg\n",
      "utility/data/training/rock/IMG_3572.JPG\n",
      "utility/data/training/rock/IMG_3651-Copy1.jpg\n",
      "utility/data/training/rock/rock3zzhao.jpg\n",
      "utility/data/training/rock/rock2zzhao.jpg\n",
      "utility/data/training/rock/20200420_184258.jpg\n",
      "utility/data/training/rock/IMG_20200423_151058589.jpg\n",
      "utility/data/training/rock/Photo on 4-23-20 at 7.27 AM #4.jpg\n",
      "utility/data/training/rock/IMG_0696.jpg\n",
      "utility/data/training/rock/IMG_7429.jpeg\n",
      "utility/data/training/rock/IMG_0132.JPG\n",
      "utility/data/training/rock/img1.jpg\n",
      "utility/data/training/rock/IMG_6027.jpg\n",
      "utility/data/training/rock/IMG_6644.jpeg\n",
      "utility/data/training/rock/IMG_3670-Copy1.jpg\n",
      "utility/data/training/rock/IMG_6345.JPG\n",
      "utility/data/training/rock/IMG_3573.JPG\n",
      "utility/data/training/rock/IMG_0085.jpg\n",
      "utility/data/training/rock/IMG_0913.JPG\n",
      "utility/data/training/rock/IMG_4290.jpg\n",
      "utility/data/training/rock/4.jpg\n",
      "utility/data/training/rock/IMG_1854.jpg\n",
      "utility/data/training/rock/IMG_4910.jpg\n",
      "utility/data/training/rock/rock2rock.jpg\n",
      "utility/data/training/rock/Rock 2.jpg\n",
      "utility/data/training/rock/Image 4.jpeg\n",
      "utility/data/training/rock/IMG-1974.jpg\n",
      "utility/data/training/rock/IMG_0342.jpg\n",
      "utility/data/training/rock/Rock 3.jpg\n",
      "utility/data/training/rock/IMG_6272.jpeg\n",
      "utility/data/training/rock/IMG_9979.jpg\n",
      "utility/data/training/rock/5.jpg\n",
      "utility/data/training/rock/IMG_4291.jpg\n",
      "utility/data/training/rock/rock4zzhao.jpg\n",
      "utility/data/training/rock/IMG_4907.jpg\n",
      "utility/data/training/rock/IMG_5358.jpg\n",
      "utility/data/training/rock/IMG_1923.jpg\n",
      "utility/data/training/rock/Rock 1.jpg\n",
      "utility/data/training/rock/IMG_2027.JPG\n",
      "utility/data/training/rock/IMG-1977.jpg\n",
      "utility/data/training/rock/IMG_20200423_151103270.jpg\n",
      "utility/data/training/rock/IMG_6638.jpeg\n",
      "utility/data/training/rock/WeChat Image_20200424001433.jpg\n",
      "utility/data/training/rock/IMG_5359.jpg\n",
      "utility/data/training/rock/IMG_1842.jpg\n",
      "utility/data/training/rock/2.jpg\n",
      "utility/data/training/rock/Rock 4.jpg\n",
      "utility/data/training/rock/93856322_1114384425571451_7685104842385129472_n.jpg\n",
      "utility/data/training/rock/WeChat Image_20200424001437.jpg\n",
      "utility/data/training/rock/IMG_0345.jpg\n",
      "utility/data/training/rock/IMG_20200423_205102.jpg\n",
      "utility/data/training/rock/IMG_1517.jpg\n",
      "utility/data/training/rock/IMG_2022.JPG\n",
      "utility/data/training/rock/IMG_6523.jpg\n",
      "utility/data/training/rock/IMG_0393.JPG\n",
      "utility/data/training/rock/WeChat Image_20200424001422.jpg\n",
      "utility/data/training/rock/IMG_5360.jpg\n",
      "utility/data/training/rock/IMG_9980.jpg\n",
      "utility/data/training/rock/3.jpg\n",
      "utility/data/training/rock/rock3rock.jpg\n",
      "utility/data/training/rock/1.jpg\n",
      "utility/data/training/rock/IMG_9982.jpg\n",
      "utility/data/training/rock/IMG_1845.jpg\n",
      "utility/data/training/rock/fakf.png\n",
      "utility/data/training/rock/IMG_6635.jpeg\n",
      "utility/data/training/rock/rock2134234242.jpg\n",
      "utility/data/training/rock/rock1jche.JPG\n",
      "utility/data/training/rock/IMG-1970.jpg\n",
      "utility/data/training/rock/IMG_20200423_205115.jpg\n",
      "utility/data/training/rock/IMG_2020.JPG\n",
      "utility/data/training/rock/Image 5.jpeg\n",
      "utility/data/training/rock/94488506_242129667151862_2255491870652104704_n.jpg\n",
      "utility/data/training/rock/IMG_9983.jpg\n",
      "utility/data/training/rock/IMG_20200423_205048.jpg\n",
      "utility/data/training/scissors/Photo on 4-23-20 at 7.28 AM #3.jpg\n",
      "utility/data/training/scissors/WIN_20200420_20_29_51_Pro.jpg\n",
      "utility/data/training/scissors/IMG_6270.jpeg\n",
      "utility/data/training/scissors/IMG_1901.jpg\n",
      "utility/data/training/scissors/IMG_6511.jpg\n",
      "utility/data/training/scissors/scissors2n.jpg\n",
      "utility/data/training/scissors/IMG_1524.jpg\n",
      "utility/data/training/scissors/IMG_3455.jpg\n",
      "utility/data/training/scissors/IMG_7140.JPG\n",
      "utility/data/training/scissors/IMG_1525.jpg\n",
      "utility/data/training/scissors/IMG-1982.jpg\n",
      "utility/data/training/scissors/sci3jche.JPG\n",
      "utility/data/training/scissors/Photo on 4-23-20 at 7.29 AM.jpg\n",
      "utility/data/training/scissors/Image 6.jpeg\n",
      "utility/data/training/scissors/IMG_9347.JPG\n",
      "utility/data/training/scissors/IMG_7140.PNG\n",
      "utility/data/training/scissors/IMG_1900.jpg\n",
      "utility/data/training/scissors/IMG_1647.jpg\n",
      "utility/data/training/scissors/IMG_1653.jpg\n",
      "utility/data/training/scissors/IMG_5384.jpg\n",
      "utility/data/training/scissors/Photo on 4-23-20 at 7.28 AM #2.jpg\n",
      "utility/data/training/scissors/IMG_4298.jpg\n",
      "utility/data/training/scissors/SCISSORS1LAB10.jpg\n",
      "utility/data/training/scissors/IMG_1902.jpg\n",
      "utility/data/training/scissors/IMG_2229.jpeg\n",
      "utility/data/training/scissors/Image 10.jpeg\n",
      "utility/data/training/scissors/IMG_6506.jpg\n",
      "utility/data/training/scissors/IMG_3456.JPG\n",
      "utility/data/training/scissors/IMG_3457.JPG\n",
      "utility/data/training/scissors/IMG_1526.jpg\n",
      "utility/data/training/scissors/feafe.png\n",
      "utility/data/training/scissors/IMG_7143.PNG\n",
      "utility/data/training/scissors/IMG_3674-Copy1.jpg\n",
      "utility/data/training/scissors/IMG_7441.jpeg\n",
      "utility/data/training/scissors/IMG_7440.jpeg\n",
      "utility/data/training/scissors/IMG_5383.jpg\n",
      "utility/data/training/scissors/IMG_7219.JPG\n",
      "utility/data/training/scissors/IMG_6640.jpeg\n",
      "utility/data/training/scissors/IMG_0452.jpeg\n",
      "utility/data/training/scissors/WIN_20200420_20_29_49_Pro.jpg\n",
      "utility/data/training/scissors/IMG_1523.jpg\n",
      "utility/data/training/scissors/IMG_20200423_151054318.jpg\n",
      "utility/data/training/scissors/IMG_2228.jpeg\n",
      "utility/data/training/scissors/IMG_7146.PNG\n",
      "utility/data/training/scissors/IMG_1899.jpg\n",
      "utility/data/training/scissors/IMG_20200423_151050963.jpg\n",
      "utility/data/training/scissors/IMG_5382.jpg\n",
      "utility/data/training/scissors/faef.png\n",
      "utility/data/training/scissors/IMG-1979.jpg\n",
      "utility/data/training/scissors/Image 7.jpeg\n",
      "utility/data/training/scissors/scissors11.jpg\n",
      "utility/data/training/scissors/scissors3n.jpg\n",
      "utility/data/training/scissors/sci2jche.JPG\n",
      "utility/data/training/scissors/IMG_6637.jpeg\n",
      "utility/data/training/scissors/IMG_3690.JPG\n",
      "utility/data/training/scissors/IMG_1642.jpg\n",
      "utility/data/training/scissors/IMG_5381.jpg\n",
      "utility/data/training/scissors/IMG_2660.jpg\n",
      "utility/data/training/scissors/Photo on 4-23-20 at 7.29 AM #3.jpg\n",
      "utility/data/training/scissors/sci1zzhao.jpg\n",
      "utility/data/training/scissors/IMG_2072.jpg\n",
      "utility/data/training/scissors/94425153_226299125345652_2141919028241760256_n.jpg\n",
      "utility/data/training/scissors/IMG_7137.JPG\n",
      "utility/data/training/scissors/IMG_0102.jpg\n",
      "utility/data/training/scissors/IMG_2073.jpg\n",
      "utility/data/training/scissors/Photo on 4-23-20 at 7.29 AM #2.jpg\n",
      "utility/data/training/scissors/IMG_9330.jpg\n",
      "utility/data/training/scissors/IMG_7137.PNG\n",
      "utility/data/training/scissors/20200420_184321.jpg\n",
      "utility/data/training/scissors/IMG_0921.JPG\n",
      "utility/data/training/scissors/IMG_3555.jpg\n",
      "utility/data/training/scissors/thumbnail_IMG_0353.jpg\n",
      "utility/data/training/scissors/20200420_184323.jpg\n",
      "utility/data/training/scissors/94259779_871740533311770_1108693657969491968_n.jpg\n",
      "utility/data/training/scissors/Scissor4.jpg\n",
      "utility/data/training/scissors/s5.jpg\n",
      "utility/data/training/scissors/IMG_0699.jpg\n",
      "utility/data/training/scissors/WIN_20200420_20_29_52_Pro.jpg\n",
      "utility/data/training/scissors/IMG_2071.jpg\n",
      "utility/data/training/scissors/scissors4n.jpg\n",
      "utility/data/training/scissors/IMG_2070.jpg\n",
      "utility/data/training/scissors/IMG_0101.jpg\n",
      "utility/data/training/scissors/s4.jpg\n",
      "utility/data/training/scissors/thumbnail_IMG_0352.jpg\n",
      "utility/data/training/scissors/thumbnail_IMG_0346.jpg\n",
      "utility/data/training/scissors/IMG_0920.JPG\n",
      "utility/data/training/scissors/IMG_0918.JPG\n",
      "utility/data/training/scissors/IMG_7050.jpg\n",
      "utility/data/training/scissors/IMG_2672.jpg\n",
      "utility/data/training/scissors/scissors9.jpg\n",
      "utility/data/training/scissors/Scissor1.jpg\n",
      "utility/data/training/scissors/WeChat Image_20200424001449.jpg\n",
      "utility/data/training/scissors/IMG_4607.JPG\n",
      "utility/data/training/scissors/scissors5n.jpg\n",
      "utility/data/training/scissors/94390391_1159638731041529_2828957025000488960_n.jpg\n",
      "utility/data/training/scissors/sci1jche.JPG\n",
      "utility/data/training/scissors/afeaf.png\n",
      "utility/data/training/scissors/s1.jpg\n",
      "utility/data/training/scissors/IMG_6277.jpeg\n",
      "utility/data/training/scissors/20200420_184327.jpg\n",
      "utility/data/training/scissors/IMG_2667.jpg\n",
      "utility/data/training/scissors/IMG_8410.jpg\n",
      "utility/data/training/scissors/IMG_0099.jpg\n",
      "utility/data/training/scissors/thumbnail_IMG_0355.jpg\n",
      "utility/data/training/scissors/IMG_2659.jpg\n",
      "utility/data/training/scissors/IMG_2665.jpg\n",
      "utility/data/training/scissors/IMG_0700.jpg\n",
      "utility/data/training/scissors/IMG_1185.JPG\n",
      "utility/data/training/scissors/20200420_184319.jpg\n",
      "utility/data/training/scissors/s3.jpg\n",
      "utility/data/training/scissors/scissors.jpg\n",
      "utility/data/training/scissors/Scissor2.jpg\n",
      "utility/data/training/scissors/IMG_6646.jpeg\n",
      "utility/data/training/scissors/IMG_9334.jpg\n",
      "utility/data/training/scissors/IMG_20200423_204936.jpg\n",
      "utility/data/training/scissors/IMG_20200423_151047649.jpg\n",
      "utility/data/training/scissors/IMG_9679.JPG\n",
      "utility/data/training/scissors/IMG_1999.jpg\n",
      "utility/data/training/scissors/Scissor3.jpg\n",
      "utility/data/training/scissors/IMG_20200423_204857.jpg\n",
      "utility/data/training/scissors/s2.jpg\n",
      "utility/data/training/scissors/20200420_184324.jpg\n",
      "utility/data/training/scissors/IMG_2670.jpg\n",
      "utility/data/training/scissors/IMG_0701.jpg\n",
      "utility/data/training/scissors/IMG_3552.jpg\n",
      "utility/data/training/scissors/IMG_2658.jpg\n",
      "utility/data/training/scissors/thumbnail_IMG_0354.jpg\n",
      "utility/data/training/scissors/94574508_163982451584274_8151333468035350528_n.jpg\n",
      "utility/data/training/scissors/IMG_0098.jpg\n",
      "utility/data/training/scissors/IMG_0917.JPG\n",
      "utility/data/training/scissors/scissors6.jpg\n",
      "utility/data/training/scissors/IMG_1638.jpg\n",
      "utility/data/training/scissors/IMG_5476.JPG\n",
      "utility/data/training/scissors/IMG_1002.JPG\n",
      "utility/data/training/scissors/IMG_0122.JPG\n",
      "utility/data/training/scissors/IMG_1572.JPG\n",
      "utility/data/training/scissors/IMG_1573.JPG\n",
      "utility/data/training/scissors/IMG_0123.JPG\n",
      "utility/data/training/scissors/IMG_1003.JPG\n",
      "utility/data/training/scissors/IMG_1639.jpg\n",
      "utility/data/training/scissors/scissors7.jpg\n",
      "utility/data/training/scissors/IMG_6340.JPG\n",
      "utility/data/training/scissors/IMG_6342.JPG\n",
      "utility/data/training/scissors/IMG_5475.JPG\n",
      "utility/data/training/scissors/Scissors 4.jpg\n",
      "utility/data/training/scissors/sci4zzhao.jpg\n",
      "utility/data/training/scissors/sci4jche.JPG\n",
      "utility/data/training/scissors/IMG_0337.jpg\n",
      "utility/data/training/scissors/IMG_6034.jpg\n",
      "utility/data/training/scissors/IMG_1571.JPG\n",
      "utility/data/training/scissors/IMG_1570.JPG\n",
      "utility/data/training/scissors/IMG_0134.JPG\n",
      "utility/data/training/scissors/IMG_6035.jpg\n",
      "utility/data/training/scissors/IMG_8636.jpg\n",
      "utility/data/training/scissors/IMG_5474.JPG\n",
      "utility/data/training/scissors/IMG_5448.JPG\n",
      "utility/data/training/scissors/IMG_6274.jpeg\n",
      "utility/data/training/scissors/afef.png\n",
      "utility/data/training/scissors/scissors4.jpg\n",
      "utility/data/training/scissors/IMG_3561.jpg\n",
      "utility/data/training/scissors/IMG_6343.JPG\n",
      "utility/data/training/scissors/IMG_2657.jpg\n",
      "utility/data/training/scissors/IMG_0726.jpg\n",
      "utility/data/training/scissors/SCISSORS2LAB10.jpg\n",
      "utility/data/training/scissors/SCISSORS3LAB10.jpg\n",
      "utility/data/training/scissors/Scissors 1.jpg\n",
      "utility/data/training/scissors/IMG_1004.JPG\n",
      "utility/data/training/scissors/IMG_20200423_204914.jpg\n",
      "utility/data/training/scissors/IMG_7139.JPG\n",
      "utility/data/training/scissors/scissors44.jpg\n",
      "utility/data/training/scissors/IMG_0124.JPG\n",
      "utility/data/training/scissors/IMG_7138.JPG\n",
      "utility/data/training/scissors/IMG_1005.JPG\n",
      "utility/data/training/scissors/WeChat Image_20200424001455.jpg\n",
      "utility/data/training/scissors/IMG_3669-Copy1.jpg\n",
      "utility/data/training/scissors/scissors1.jpg\n",
      "utility/data/training/scissors/IMG_3558.jpg\n",
      "utility/data/training/scissors/IMG_20200423_205002.jpg\n",
      "utility/data/training/scissors/IMG_6344.JPG\n",
      "utility/data/training/scissors/scissors3.jpg\n",
      "utility/data/training/scissors/IMG_5473.JPG\n",
      "utility/data/training/scissors/WeChat Image_20200424001443.jpg\n",
      "utility/data/training/scissors/Scissors 2.jpg\n",
      "utility/data/training/scissors/IMG_9329.jpg\n",
      "utility/data/training/scissors/IMG_8779.JPG\n",
      "utility/data/training/scissors/IMG_6032.jpg\n",
      "utility/data/training/scissors/IMG_3645-Copy1.jpg\n",
      "utility/data/training/scissors/IMG_0697.jpg\n",
      "utility/data/training/scissors/IMG_6033.jpg\n",
      "utility/data/training/scissors/IMG_9328.jpg\n",
      "utility/data/training/scissors/Scissors 3.jpg\n",
      "utility/data/training/scissors/scissors2.jpg\n",
      "utility/data/training/scissors/wscissors4.jpg\n",
      "utility/data/training/scissors/4.jpg\n",
      "utility/data/training/scissors/IMG_9978.jpg\n",
      "utility/data/training/scissors/IMG-6465 (1).jpg\n",
      "utility/data/training/scissors/IMG_5159.jpg\n",
      "utility/data/training/scissors/IMG_9987.jpg\n",
      "utility/data/training/scissors/94510946_219159649373987_1493523595274485760_n.jpg\n",
      "utility/data/training/scissors/SCISSORS4LAB10.jpg\n",
      "utility/data/training/scissors/IMG_0343.jpg\n",
      "utility/data/training/scissors/Photo on 4-22-20 at 2.27 PM #5.jpg\n",
      "utility/data/training/scissors/IMG_0419.JPG\n",
      "utility/data/training/scissors/IMG_6295.jpg\n",
      "utility/data/training/scissors/IMG_2030.JPG\n",
      "utility/data/training/scissors/IMG_2024.JPG\n",
      "utility/data/training/scissors/Photo on 4-22-20 at 2.27 PM #4.jpg\n",
      "utility/data/training/scissors/IMG_2227.jpeg\n",
      "utility/data/training/scissors/IMG_5366.jpg\n",
      "utility/data/training/scissors/IMG_9986.jpg\n",
      "utility/data/training/scissors/5.jpg\n",
      "utility/data/training/scissors/IMG_4293.jpg\n",
      "utility/data/training/scissors/IMG_4913.jpg\n",
      "utility/data/training/scissors/IMG_5364.jpg\n",
      "utility/data/training/scissors/IMG_20200423_151057191.jpg\n",
      "utility/data/training/scissors/IMG_6643.jpeg\n",
      "utility/data/training/scissors/IMG-1976.jpg\n",
      "utility/data/training/scissors/scissors22.jpg\n",
      "utility/data/training/scissors/IMG_3463.jpg\n",
      "utility/data/training/scissors/IMG_2026.JPG\n",
      "utility/data/training/scissors/IMG_6268.jpeg\n",
      "utility/data/training/scissors/IMG_0341.jpg\n",
      "utility/data/training/scissors/IMG_5365.jpg\n",
      "utility/data/training/scissors/IMG_9985.jpg\n",
      "utility/data/training/scissors/2.jpg\n",
      "utility/data/training/scissors/wscissors2.jpg\n",
      "utility/data/training/scissors/IMG_9981.jpg\n",
      "utility/data/training/scissors/IMG_7439.jpeg\n",
      "utility/data/training/scissors/IMG_4916.jpg\n",
      "utility/data/training/scissors/IMG_3649-Copy1.jpg\n",
      "utility/data/training/scissors/Photo on 4-22-20 at 2.27 PM #3.jpg\n",
      "utility/data/training/scissors/scissors33.jpg\n",
      "utility/data/training/scissors/Image 9.jpeg\n",
      "utility/data/training/scissors/IMG-1972.jpg\n",
      "utility/data/training/scissors/Photo on 4-22-20 at 2.27 PM #2.jpg\n",
      "utility/data/training/scissors/ss02.jpg\n",
      "utility/data/training/scissors/IMG_1853.jpg\n",
      "utility/data/training/scissors/IMG_1847.jpg\n",
      "utility/data/training/scissors/IMG_5162.jpg\n",
      "utility/data/training/scissors/wscissors3.jpg\n",
      "utility/data/training/scissors/3.jpg\n",
      "utility/data/training/scissors/IMG_7442.jpeg\n",
      "utility/data/training/scissors/IMG_4295.jpg\n",
      "utility/data/training/scissors/wscissors1.jpg\n",
      "utility/data/training/scissors/1.jpg\n",
      "utility/data/training/scissors/IMG_5160.jpg\n",
      "utility/data/training/scissors/IMG_4915.jpg\n",
      "utility/data/training/scissors/IMG_2226.jpeg\n",
      "utility/data/training/scissors/IMG_4134.jpg\n",
      "utility/data/training/scissors/sci2zzhao.jpg\n",
      "utility/data/training/scissors/sci3zzhao.jpg\n",
      "utility/data/training/scissors/IMG_6509.jpg\n",
      "utility/data/training/scissors/IMG_2021.JPG\n",
      "utility/data/training/scissors/IMG_6521.jpg\n",
      "utility/data/training/scissors/IMG_3458.JPG\n",
      "utility/data/training/scissors/WIN_20200420_20_29_54_Pro.jpg\n",
      "utility/data/training/scissors/IMG_0347.jpg\n",
      "utility/data/training/scissors/WeChat Image_20200424001409.jpg\n",
      "utility/data/training/scissors/IMG_5363.jpg\n",
      "utility/data/training/scissors/IMG_1844.jpg\n",
      "utility/data/training/scissors/IMG_1850.jpg\n",
      "utility/data/training/scissors/IMG_4914.jpg\n",
      "utility/data/training/scissors/IMG_5161.jpg\n",
      "utility/data/training/scissors/IMG_4294.jpg\n",
      "utility/data/validation/paper/IMG_5390.jpg\n",
      "utility/data/validation/paper/IMG_5147.jpg\n",
      "utility/data/validation/paper/IMG_9977.jpg\n",
      "utility/data/validation/paper/IMG_6339.JPG\n",
      "utility/data/validation/paper/IMG_1898.jpg\n",
      "utility/data/validation/paper/IMG-1984.jpg\n",
      "utility/data/validation/paper/20200420_184230.jpg\n",
      "utility/data/validation/paper/94207753_959390134481555_1516703722749558784_n.jpg\n",
      "utility/data/validation/paper/paper4.jpg\n",
      "utility/data/validation/paper/Paper5.jpg\n",
      "utility/data/validation/paper/IMG_9324.jpg\n",
      "utility/data/validation/paper/IMG_3184.jpg\n",
      "utility/data/validation/paper/IMG_3183.jpg\n",
      "utility/data/validation/paper/IMG_0139.JPG\n",
      "utility/data/validation/paper/IMG_7130.JPG\n",
      "utility/data/validation/paper/paper2.jpg\n",
      "utility/data/validation/paper/IMG_3182.jpg\n",
      "utility/data/validation/paper/paper5zzhao.jpg\n",
      "utility/data/validation/paper/WeChat Image_20200424001514.jpg\n",
      "utility/data/validation/paper/IMG_3551.jpg\n",
      "utility/data/validation/paper/IMG_2214.jpeg\n",
      "utility/data/validation/paper/wpaper5.jpg\n",
      "utility/data/validation/paper/Paper1.jpg\n",
      "utility/data/validation/paper/IMG_2063.jpg\n",
      "utility/data/validation/paper/IMG_0477.JPG\n",
      "utility/data/validation/paper/IMG_3181.jpg\n",
      "utility/data/validation/paper/IMG_1610.jpg\n",
      "utility/data/validation/paper/IMG_3198.jpg\n",
      "utility/data/validation/paper/IMG_0334.jpg\n",
      "utility/data/validation/paper/IMG_8027.JPG\n",
      "utility/data/validation/paper/IMG_1536.HEIC\n",
      "utility/data/validation/paper/IMG_6278.jpeg\n",
      "utility/data/validation/paper/IMG_2654.jpg\n",
      "utility/data/validation/paper/paper5jche.JPG\n",
      "utility/data/validation/paper/IMG_1001.JPG\n",
      "utility/data/validation/paper/rescaled5.jpg\n",
      "utility/data/validation/paper/p1.jpg\n",
      "utility/data/validation/paper/IMG_20200423_151020958.jpg\n",
      "utility/data/validation/paper/IMG_0911.JPG\n",
      "utility/data/validation/paper/IMG_0087.jpg\n",
      "utility/data/validation/paper/p5.jpg\n",
      "utility/data/validation/paper/IMG_9316.jpg\n",
      "utility/data/validation/paper/IMG_1574.JPG\n",
      "utility/data/validation/paper/IMG_6648.jpeg\n",
      "utility/data/validation/paper/IMG_2652.jpg\n",
      "utility/data/validation/paper/IMG_6026.jpg\n",
      "utility/data/validation/paper/Image 15.jpeg\n",
      "utility/data/validation/paper/IMG_5466.JPG\n",
      "utility/data/validation/paper/4.jpg\n",
      "utility/data/validation/paper/Photo on 4-22-20 at 2.28 PM.jpg\n",
      "utility/data/validation/paper/IMG_7149.PNG\n",
      "utility/data/validation/paper/IMG_20200423_204838.jpg\n",
      "utility/data/validation/paper/c.png\n",
      "utility/data/validation/paper/IMG_3644 (1) (1).jpg\n",
      "utility/data/validation/paper/5.jpg\n",
      "utility/data/validation/paper/IMG_1843.jpg\n",
      "utility/data/validation/paper/IMG_7438.jpeg\n",
      "utility/data/validation/paper/IMG_4279.jpg\n",
      "utility/data/validation/paper/IMG_2036.JPG\n",
      "utility/data/validation/paper/94624216_159517542104879_9146173040546021376_n.jpg\n",
      "utility/data/validation/paper/IMG_5376.jpg\n",
      "utility/data/validation/paper/Paper 5.jpg\n",
      "utility/data/validation/paper/IMG_6508.jpg\n",
      "utility/data/validation/paper/paper55.jpg\n",
      "utility/data/validation/paper/PAPER4LAB10.jpg\n",
      "utility/data/validation/paper/WIN_20200420_20_29_36_Pro.jpg\n",
      "utility/data/validation/rock/IMG-1983.jpg\n",
      "utility/data/validation/rock/IMG_5152.jpg\n",
      "utility/data/validation/rock/IMG_0994.JPG\n",
      "utility/data/validation/rock/IMG_7147.PNG\n",
      "utility/data/validation/rock/IMG_1521.jpg\n",
      "utility/data/validation/rock/WeChat Image_20200424001428.jpg\n",
      "utility/data/validation/rock/fafi.png\n",
      "utility/data/validation/rock/IMG_5395.jpg\n",
      "utility/data/validation/rock/IMG_3643 (1) (1).jpg\n",
      "utility/data/validation/rock/rock5jche.JPG\n",
      "utility/data/validation/rock/IMG_1369.JPG\n",
      "utility/data/validation/rock/94377537_2542546856000210_6059336652856229888_n.jpg\n",
      "utility/data/validation/rock/IMG_6348.JPG\n",
      "utility/data/validation/rock/IMG_3191.jpg\n",
      "utility/data/validation/rock/ROCK5LAB10.jpg\n",
      "utility/data/validation/rock/IMG_7136.JPG\n",
      "utility/data/validation/rock/rock3n.jpg\n",
      "utility/data/validation/rock/IMG_2663.jpg\n",
      "utility/data/validation/rock/IMG_20200423_151043207.jpg\n",
      "utility/data/validation/rock/rock0.jpg\n",
      "utility/data/validation/rock/IMG_3192.jpg\n",
      "utility/data/validation/rock/IMG_2065.jpg\n",
      "utility/data/validation/rock/IMG_1579.JPG\n",
      "utility/data/validation/rock/IMG_3193.jpg\n",
      "utility/data/validation/rock/Rock5.jpg\n",
      "utility/data/validation/rock/WIN_20200420_20_29_31_Pro.jpg\n",
      "utility/data/validation/rock/r5.jpg\n",
      "utility/data/validation/rock/IMG_20200423_205223.jpg\n",
      "utility/data/validation/rock/IMG_2659.jpg\n",
      "utility/data/validation/rock/IMG_6650.jpeg\n",
      "utility/data/validation/rock/IMG_3194.jpg\n",
      "utility/data/validation/rock/wrock5.jpg\n",
      "utility/data/validation/rock/IMG_9321.jpg\n",
      "utility/data/validation/rock/IMG_3195.jpg\n",
      "utility/data/validation/rock/20200420_184249.jpg\n",
      "utility/data/validation/rock/img5.jpg\n",
      "utility/data/validation/rock/IMG_5477.JPG\n",
      "utility/data/validation/rock/IMG_3562.jpg\n",
      "utility/data/validation/rock/IMG_0916.JPG\n",
      "utility/data/validation/rock/IMG_0082.jpg\n",
      "utility/data/validation/rock/Image 2.jpeg\n",
      "utility/data/validation/rock/IMG_0135.JPG\n",
      "utility/data/validation/rock/IMG_2535.jpg\n",
      "utility/data/validation/rock/IMG_7433.jpeg\n",
      "utility/data/validation/rock/IMG_2220.jpeg\n",
      "utility/data/validation/rock/IMG-6467 (1).jpg\n",
      "utility/data/validation/rock/IMG_6031.jpg\n",
      "utility/data/validation/rock/IMG_0333.jpg\n",
      "utility/data/validation/rock/20200420_184306.jpg\n",
      "utility/data/validation/rock/IMG_6280.jpeg\n",
      "utility/data/validation/rock/IMG_8793.jpg\n",
      "utility/data/validation/rock/rock_resize.png\n",
      "utility/data/validation/rock/IMG_1908.jpg\n",
      "utility/data/validation/rock/IMG_6519.jpg\n",
      "utility/data/validation/rock/5.jpg\n",
      "utility/data/validation/rock/IMG_4287.jpg\n",
      "utility/data/validation/rock/rock5zzhao.jpg\n",
      "utility/data/validation/rock/IMG_9984.jpg\n",
      "utility/data/validation/rock/IMG_2032.JPG\n",
      "utility/data/validation/rock/IMG_0393.JPG\n",
      "utility/data/validation/rock/Rock 5.jpg\n",
      "utility/data/validation/rock/1.jpg\n",
      "utility/data/validation/rock/IMG_1851.jpg\n",
      "utility/data/validation/rock/IMG_5362.jpg\n",
      "utility/data/validation/rock/Photo on 4-22-20 at 2.26 PM.jpg\n",
      "utility/data/validation/rock/94488506_242129667151862_2255491870652104704_n.jpg\n",
      "utility/data/validation/scissors/IMG_5385.jpg\n",
      "utility/data/validation/scissors/IMG_2225.jpeg\n",
      "utility/data/validation/scissors/IMG_7141.JPG\n",
      "utility/data/validation/scissors/IMG_3252.jpg\n",
      "utility/data/validation/scissors/IMG_5147.jpg\n",
      "utility/data/validation/scissors/IMG_1903.jpg\n",
      "utility/data/validation/scissors/IMG-1985.jpg\n",
      "utility/data/validation/scissors/IMG_5369.jpg\n",
      "utility/data/validation/scissors/IMG_4698.JPG\n",
      "utility/data/validation/scissors/IMG_0922.JPG\n",
      "utility/data/validation/scissors/94425153_226299125345652_2141919028241760256_n.jpg\n",
      "utility/data/validation/scissors/IMG_3190.jpg\n",
      "utility/data/validation/scissors/IMG_2661.jpg\n",
      "utility/data/validation/scissors/94259779_871740533311770_1108693657969491968_n.jpg\n",
      "utility/data/validation/scissors/s5.jpg\n",
      "utility/data/validation/scissors/IMG_3186.jpg\n",
      "utility/data/validation/scissors/IMG_20200423_151045071.jpg\n",
      "utility/data/validation/scissors/IMG_9327.jpg\n",
      "utility/data/validation/scissors/IMG_3187.jpg\n",
      "utility/data/validation/scissors/Scissor5.jpg\n",
      "utility/data/validation/scissors/IMG_1569.JPG\n",
      "utility/data/validation/scissors/IMG_2074.jpg\n",
      "utility/data/validation/scissors/s1.jpg\n",
      "utility/data/validation/scissors/Photo on 4-22-20 at 2.27 PM.jpg\n",
      "utility/data/validation/scissors/20200420_184327.jpg\n",
      "utility/data/validation/scissors/20200420_184319.jpg\n",
      "utility/data/validation/scissors/IMG_9679.JPG\n",
      "utility/data/validation/scissors/IMG_2664.jpg\n",
      "utility/data/validation/scissors/IMG_6341.JPG\n",
      "utility/data/validation/scissors/WeChat Image_20200424001452.jpg\n",
      "utility/data/validation/scissors/IMG_3642 (1) (1).jpg\n",
      "utility/data/validation/scissors/IMG_0137.JPG\n",
      "utility/data/validation/scissors/IMG_0335.jpg\n",
      "utility/data/validation/scissors/IMG_6036.jpg\n",
      "utility/data/validation/scissors/IMG_0096.jpg\n",
      "utility/data/validation/scissors/sci5zzhao.jpg\n",
      "utility/data/validation/scissors/IMG_6649.jpeg\n",
      "utility/data/validation/scissors/scissors55.jpg\n",
      "utility/data/validation/scissors/Scissors 5.jpg\n",
      "utility/data/validation/scissors/WIN_20200420_20_29_56_Pro.jpg\n",
      "utility/data/validation/scissors/IMG_3549.jpg\n",
      "utility/data/validation/scissors/IMG_4222.jpg\n",
      "utility/data/validation/scissors/scissors0.jpg\n",
      "utility/data/validation/scissors/sci5jche.JPG\n",
      "utility/data/validation/scissors/scissors1.jpg\n",
      "utility/data/validation/scissors/IMG_20200423_205016.jpg\n",
      "utility/data/validation/scissors/IMG_6279.jpeg\n",
      "utility/data/validation/scissors/IMG_1537.heic\n",
      "utility/data/validation/scissors/IMG_3189.jpg\n",
      "utility/data/validation/scissors/IMG_1006.JPG\n",
      "utility/data/validation/scissors/IMG_3188.jpg\n",
      "utility/data/validation/scissors/IMG_5472.JPG\n",
      "utility/data/validation/scissors/SCISSORS5LAB10.jpg\n",
      "utility/data/validation/scissors/afe.png\n",
      "utility/data/validation/scissors/IMG_7148.PNG\n",
      "utility/data/validation/scissors/IMG_6525.jpg\n",
      "utility/data/validation/scissors/5.jpg\n",
      "utility/data/validation/scissors/wscissors5.jpg\n",
      "utility/data/validation/scissors/IMG_7443.jpeg\n",
      "utility/data/validation/scissors/Image 8.jpeg\n",
      "utility/data/validation/scissors/IMG_1856.jpg\n",
      "utility/data/validation/scissors/IMG_4292.jpg\n",
      "utility/data/validation/scissors/2.jpg\n",
      "utility/data/validation/scissors/IMG_9981.jpg\n",
      "utility/data/validation/scissors/IMG_2037.JPG\n",
      "utility/data/validation/scissors/scissors1n.jpg\n"
     ]
    }
   ],
   "source": [
    "from utility.util import load_dataset\n",
    "\n",
    "target_shape = (500, 500)\n",
    "X_test, y_test = load_dataset('utility/data/testing', target_shape)\n",
    "X_train, y_train = load_dataset('utility/data/training', target_shape)\n",
    "X_val, y_val = load_dataset('utility/data/validation', target_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cse217_v1 accuracies:\n",
      "Number of pictures predicted correctly by model: 4\n",
      "Number of picutres in the dataset: 15\n",
      "testing accuracy\n",
      "0.26666666666666666\n",
      "\n",
      "Number of pictures predicted correctly by model: 348\n",
      "Number of picutres in the dataset: 784\n",
      "training accuracy:\n",
      "0.44387755102040816\n",
      "\n",
      "Number of pictures predicted correctly by model: 76\n",
      "Number of picutres in the dataset: 195\n",
      "validation accuracy:\n",
      "0.38974358974358975\n",
      "\n",
      "cse217_v2 accuracies:\n",
      "Number of pictures predicted correctly by model: 6\n",
      "Number of picutres in the dataset: 15\n",
      "testing accuracy\n",
      "0.4\n",
      "\n",
      "Number of pictures predicted correctly by model: 428\n",
      "Number of picutres in the dataset: 784\n",
      "training accuracy:\n",
      "0.5459183673469388\n",
      "\n",
      "Number of pictures predicted correctly by model: 82\n",
      "Number of picutres in the dataset: 195\n",
      "validation accuracy:\n",
      "0.4205128205128205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (Re)create validation (or testing) dataset\n",
    "import skimage\n",
    "import numpy as np\n",
    "\n",
    "def accuracy(X, y, model):\n",
    "    acc = 0\n",
    "    label =  y\n",
    "    image = X\n",
    "    patchsize = model.input_shape[1]\n",
    "    for i in range(0,len(X)):\n",
    "        image_tran = skimage.transform.resize(image[i], (patchsize,patchsize))\n",
    "        outs = model.predict(np.array([image_tran]))\n",
    "        predicted = np.argmax(outs)\n",
    "        if label[i,predicted] == 1:\n",
    "            acc+=1\n",
    "    \n",
    "    print(\"Number of pictures predicted correctly by model: %d\" % acc)\n",
    "    print(\"Number of picutres in the dataset: %d\" % len(X))\n",
    "\n",
    "    return acc/len(X)\n",
    "\n",
    "\n",
    "# Compute Model Performance\n",
    "\n",
    "print(\"cse217_v1 accuracies:\")\n",
    "cse217_v1_test = accuracy(X_test, y_test, cse217_v1) \n",
    "print(\"testing accuracy\"),\n",
    "print(cse217_v1_test)\n",
    "print()\n",
    "\n",
    "cse217_v1_train = accuracy(X_train, y_train, cse217_v1)\n",
    "print(\"training accuracy:\"),\n",
    "print(cse217_v1_train)\n",
    "print()\n",
    "\n",
    "cse217_v1_val = accuracy(X_val, y_val, cse217_v1)\n",
    "print(\"validation accuracy:\"),\n",
    "print(cse217_v1_val)\n",
    "print()\n",
    "\n",
    "print(\"cse217_v2 accuracies:\")\n",
    "cse217_v2_test = accuracy(X_test, y_test, cse217_v2)\n",
    "print(\"testing accuracy\"),\n",
    "print(cse217_v2_test)\n",
    "print()\n",
    "\n",
    "cse217_v2_train = accuracy(X_train, y_train, cse217_v2)\n",
    "print(\"training accuracy:\"),\n",
    "print(cse217_v2_train)\n",
    "print()\n",
    "\n",
    "cse217_v2_val = accuracy(X_val, y_val, cse217_v2)\n",
    "print(\"validation accuracy:\"),\n",
    "print(cse217_v2_val)\n",
    "print()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "              | training acc | validation acc | testing acc \n",
    "    cse217_v1 |  44.39%      |  38.97%        |  26.67%\n",
    "    cse217_v2 |  54.59%      |  42.05%        |  40.00%\n",
    "\n",
    "# your response here\n",
    "\n",
    "From the above results, version 2 of cse217 performs quite a bit better than v1 in all aspects. This is likely due to the immense difference in the number of parameters between the two models. I don't think we can be happy with this because even with the better model, it is only getting the right prediction about half of the time. This is analogous to flipping a coin to determine yes or no for each image; not good. I would suggest adding more parameters to increase the accuracies of both. Additionally, adding augemented images to train both (which is actually what will happen) and/or increasing the amount of data used to train the model will help, as many images are wildly different in composure, even if the hands themselves look relatively the same. Increasing the model's \"experience\" will be beneficial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4\n",
    "\n",
    "Now, that we have summarized and analyzed the average performance of the models, let's look at individual images. \n",
    "\n",
    "**Write-up**  Using your own `testing` set and the better performing version that you identified in the previous problem, which of the three classes get predicted more correctly, which of the classes get mistaken for what other classes more frequently? \n",
    "\n",
    "> Hint: you may use the visualization implemented in the *updated version* of  `Lab10_Model` under `5. Evaluate Neural Network on Validation Data` (last code cell).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:00<00:00, 21.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found directory utility/data/testing/rock containing class rock\n",
      "Found directory utility/data/testing/paper containing class paper\n",
      "Found directory utility/data/testing/scissors containing class scissors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 21.74it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 23.89it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 23.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_for_evaluation = \"testing\"\n",
    "\n",
    "from utility.lab import create_user_testdata\n",
    "base_directory = pathlib.Path(\"utility/data\")\n",
    "dataset_test = create_user_testdata(base_directory,data_for_evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results on individual testing inputs: \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff2e33bc6f774c50ac409b69d41da6dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, continuous_update=False, description='i', max=14), Output()), _dom_clâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.resultsShow(i, data, model)>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do the imports again (in case you start executing from here!)\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import skimage\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "def resultsShow(i, data, model):\n",
    "    guide = { 0:\"rock\",1:\"paper\",2:\"scissor\"}\n",
    "    d = data.iloc[i]\n",
    "    im = d[\"image\"]\n",
    "    l = d[\"label\"]\n",
    "    fig,axs = plt.subplots(nrows=1,ncols=3,figsize=(15,5),gridspec_kw={'width_ratios':[1,1,0.5]})\n",
    "    \n",
    "    imt = imr = skimage.transform.resize(im, (model.input_shape[1],model.input_shape[1]))\n",
    "    axs[0].imshow(im)\n",
    "    axs[0].set_title(\"Image (true class: {})\".format(names[l]))\n",
    "    \n",
    "    axs[1].imshow(imt,interpolation=\"nearest\")\n",
    "    axs[1].set_title(\"Network input\")\n",
    "    \n",
    "    outs = model.predict(np.array([imt]))\n",
    "    predicted = np.argmax(outs)\n",
    "    print(outs)\n",
    "    print(\"predicted label, %s\" % guide.get(predicted))\n",
    "    print(\"actual label, %s\"% guide.get(l))\n",
    "\n",
    "    axs[2].bar(np.array(range(len(names)))-0.5, outs[0,:], 1, color=\"gray\")\n",
    "    axs[2].set_ylim([0,1])\n",
    "    axs[2].set_xticks(range(len(names)))\n",
    "    axs[2].set_xticklabels(names)\n",
    "    axs[2].set_ylabel(\"probability\")\n",
    "    axs[2].set_xlabel(\"class\")\n",
    "    axs[2].set_title(\"Network output\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    #fig.savefig(\"out_{:05d}_{}.png\".format(i,(\"ok\" if predicted==l else \"ko\")))    \n",
    "\n",
    "# Visualize Predictions    \n",
    "print(\"Results on individual {} inputs: \".format(dataset_val.loc[0].dn))  \n",
    "interact(resultsShow, i=widgets.IntSlider(min=0,max=len(dataset_test)-1, step=1, value=0, continuous_update=False), data=fixed(dataset_test.sample(len(dataset_test))), model=fixed(cse217_v2))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# your response here\n",
    "\n",
    "Which of the three classes get predicted more correctly, which of the...?\n",
    "\n",
    "The class that was predicted correctly the most is scissors (3 out of 5 scissors identified correctly). Rock was mistaken for scissors the most at 4 times; rock was also mistaken for scissors twice. These two combined were definitely messed up most overall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Comparison: original vs augmented\n",
    "\n",
    "Now, let's investiage whether data augmentation imporves performance. \n",
    "\n",
    "\n",
    "### Problem 5\n",
    "\n",
    "Which of the models `cse217_vx`  or `cse217_vx_augmented` for both versions performs better? You can again use the code provided in the *updated version* of `Lab10_Model` under `5. Evaluate Neural Network on Validation Data` with light modifications. \n",
    "\n",
    "**Write-up** Report and compare the accuracy on all three datasets `training`, `validation`, and `testing` of the original and the augmented model for both versions. Summarize your findings. \n",
    "- Did data augemntation help? \n",
    "- Which of the two NN versions benefited or suffered more from data augmentation? \n",
    "- Give an explanation/guestimate why this is the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cse217_v1_aug accuracies:\n",
      "Number of pictures predicted correctly by model: 6\n",
      "Number of picutres in the dataset: 15\n",
      "testing accuracy\n",
      "0.4\n",
      "\n",
      "Number of pictures predicted correctly by model: 511\n",
      "Number of picutres in the dataset: 784\n",
      "training accuracy:\n",
      "0.6517857142857143\n",
      "\n",
      "Number of pictures predicted correctly by model: 122\n",
      "Number of picutres in the dataset: 195\n",
      "validation accuracy:\n",
      "0.6256410256410256\n",
      "\n",
      "cse217_v2_aug accuracies:\n",
      "Number of pictures predicted correctly by model: 5\n",
      "Number of picutres in the dataset: 15\n",
      "testing accuracy\n",
      "0.4\n",
      "\n",
      "Number of pictures predicted correctly by model: 314\n",
      "Number of picutres in the dataset: 784\n",
      "training accuracy:\n",
      "0.4005102040816326\n",
      "\n",
      "Number of pictures predicted correctly by model: 80\n",
      "Number of picutres in the dataset: 195\n",
      "validation accuracy:\n",
      "0.41025641025641024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"cse217_v1_aug accuracies:\")\n",
    "cse217_v1_aug_test = accuracy(X_test, y_test, cse217_v1_augmented) \n",
    "print(\"testing accuracy\"),\n",
    "print(cse217_v1_aug_test)\n",
    "print()\n",
    "\n",
    "cse217_v1_aug_train = accuracy(X_train, y_train, cse217_v1_augmented)\n",
    "print(\"training accuracy:\"),\n",
    "print(cse217_v1_aug_train)\n",
    "print()\n",
    "\n",
    "cse217_v1_aug_val = accuracy(X_val, y_val, cse217_v1_augmented)\n",
    "print(\"validation accuracy:\"),\n",
    "print(cse217_v1_aug_val)\n",
    "print()\n",
    "\n",
    "print(\"cse217_v2_aug accuracies:\")\n",
    "cse217_v2_aug_test = accuracy(X_test, y_test, cse217_v2_augmented)\n",
    "print(\"testing accuracy\"),\n",
    "print(cse217_v2_test)\n",
    "print()\n",
    "\n",
    "cse217_v2_aug_train = accuracy(X_train, y_train, cse217_v2_augmented)\n",
    "print(\"training accuracy:\"),\n",
    "print(cse217_v2_aug_train)\n",
    "print()\n",
    "\n",
    "cse217_v2_aug_val = accuracy(X_val, y_val, cse217_v2_augmented)\n",
    "print(\"validation accuracy:\"),\n",
    "print(cse217_v2_aug_val)\n",
    "print()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "                      | training acc | validation acc | testing acc \n",
    "            cse217_v1 |  44.39%      |  38.97%        |  26.67%\n",
    "  cse217_v1_augmented |  65.18%      |  62.56%        |  40.00%\n",
    "  \n",
    "  \n",
    "                      | training acc | validation acc | testing acc \n",
    "            cse217_v2 |  54.59%      |  42.05%        |  40.00%\n",
    "  cse217_v2_augmented |  40.05%      |  41.03%        |  40.00%\n",
    "\n",
    "# your response here\n",
    "\n",
    "- Did data augmentation help? \n",
    "  For version one, it definitely did (and by a lot). For version two, however, it actually made it worse. I think a model with less parameters benefits from being trained with augmented data. I feel it gives the model more benefit in the sense that it is simpler and more easily improvable with augmented training data. For v2, I think it reduced accuracy because of \"too much stuff.\" Having millions of parameters in addition to more training data using the augmented images I feel could be too much and causing the model to \"mess up\" and \"dip down\" in performance (parabolic trend maybe). I am speculating a bit but if a neural network were to have an \"optimal training capacity\" then it would make sense that performance is reduced when it is \"overloaded.\"\n",
    "  \n",
    "- Which of the two NN versions benefited or suffered more from data augmentation? \n",
    "   v1 benefited a lot from data augmentation. v2 suffered from data augmentation.\n",
    "   \n",
    "- Give an explanation/guestimate why this is the case.\n",
    "   Explanation/guestimate for these two stated in first question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding this box because of my strange issues (private Piazza post to Prof. Garnett). I ended up loading my files into a friend's computer and ran it successfully. The updated results for cse217_v2_augmented are displayed here (and are more on par with what one would expect for cse217_v2_augmented):\n",
    "\n",
    "   Updated v2 augmented results:\n",
    "   \n",
    "   cse217_v2_augmented |  79.85%      |  72.82%        |  66.67%\n",
    "   \n",
    "-Did data augmentation help?\n",
    "   This time, it definitely did help version 2 (by a lot). My original hypothesis with why version 2 augmented did worse is no longer valid. Having the augmented images definitely helped with accuracy and this is what we would expect (for both v1 and v2). The model has more \"experience\" because of the augmented images and as a result, has an \"easier\" time classifying images correctly/more accurate. The increased diversity helped make the model less sensitive to noise and was thus \"better trained\" for our purposes. Note: my friend said his results were weird too (on his laptop). When we tried it on a much more powerful desktop, all of our issues went away.\n",
    "   \n",
    "-Which of the two NN versions benefited or suffered more from data augmentation?\n",
    "    both benefited a lot from data augmentation.\n",
    "\n",
    "-Give an explanation/guestimate why this is the case.\n",
    "   Explanation/guestimate for these two stated in first question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6\n",
    "\n",
    "Now, let's have some fun! \n",
    "\n",
    "Let's explore a _real-time_ version of the model you identified as performing best running with your webcam. Open a new terminal window (on Mac OS you will need to use the built-in terminal app) and navigate to the directory, where you stored the model. Once there, run the following command, substituting `<model_name>` for the name of the file containing your model:\n",
    "\n",
    "```\n",
    "$ python(3) realtime.py <model_name>\n",
    "```\n",
    "\n",
    "Have fun!\n",
    "\n",
    "Note, `realtime.py` uses opencv, so you miht need to install it: \n",
    "\n",
    "- **opencv**: `pip(3) install opencv-python`\n",
    "\n",
    "\n",
    "**Write-up**  Summarize the performance of our NN model. \n",
    "- When does it work well, when does it have difficulties in predicting the correct gesture? Consider angle, background, and distance in your answer.  \n",
    "- Which of the three classes get predicted more correctly, which of the classes get mistaken for what other classes more frequently? "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# your response here\n",
    "\n",
    "Answered these questions with respect to my experience without using realtime.py.\n",
    "\n",
    "When does it work well, when does it...?\n",
    "\n",
    "It works well when there aren't things that look like fingers in the fist area. When a fist was made for \"rock,\" it was very commonly mistaken for paper, where the palm is open with fingers outstretched. It was also pretty common for scissors to be mistaken for rock. This is likely because the scissors form with the hand is still \"semi-rock\"-like with three fingers closed in. In general, it seems that it was quite easy for everything to be mixed up. I think it is all likely because of having fingers clearly visibile, which can cause confusion between the shapes (in my particular pictures since my hand was always oriented with the palm facing the camera).\n",
    "\n",
    "It is a bit hard to say but it also (generally) appears to work better with a more distinctly colored background. For some of my testing images, wall color was similar to my hand color. The model never predicited those correctly and assigned very similar probabilities to all classes, where the final prediction was only a tiny bit higher in probability than the others. The other backgrounds resulted in more drastic probability differences, though most of those were predicted incorrectly as well.\n",
    "\n",
    "I also feel like my hand was a little too close to the camera for most of the shots. In some of the correctly predicted ones, I noticed that my hand was a little bit further away. The difference this makes is hard to tell with only 15 samples, but could be a factor.\n",
    "\n",
    "I can't comment much on angle besides the fact that every picture, I had my \"palm\" facing the camera. Not sure if it would have made a difference if I had rotated my hand around. However, from my analysis in the first paragraph of this box, I do think having all fingers shown messes up the model. So there is likely some truth in saying that rotating the hand the other way to make the \"palm area\" less \"messy\" could help with prediction accuracy. This way, the fingers that distinguish rock, paper, and scissors from each other can be more prominent. Following this, the model could be skewed from training, because of a lack of \"palm facing camera\" shots, and be predominantly looking for 2 fingers for scissors, 5 fingers for paper, and none for rock.\n",
    "\n",
    "In short, it works better when the background is more different in color than the hand, when there are less fingers in the pose/palm is angled away from the camera; less fingers in the shot, and when it is a little bit further away (approx. 2 feet I'd say).\n",
    "\n",
    "------------------------------------------------\n",
    "\n",
    "Which of the three classes gets predicted...?\n",
    "\n",
    "-assuming this is asking the same thing as problem 4.\n",
    "-The class that was predicted correctly the most is scissors (3 out of 5 scissors identified correctly). Rock was mistaken for scissors the most at 4 times; rock was also mistaken for scissors twice. These two combined were definitely messed up most overall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it! Remember to review your work and make sure it is well presented and organized. Not everyting you coded up needs to remain in your submission, infact for this hw, we arenot expecting any code submission. **[Does [this cell] spark joy?](https://i.kinja-img.com/gawker-media/image/upload/s--iW_3HGbT--/c_scale,dpr_2.0,f_auto,fl_progressive,q_80,w_800/oruf4oavtj5vpmvaquew.jpg)** You are always trying to communicate your findings to somebody, _maybe even yourself_."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
